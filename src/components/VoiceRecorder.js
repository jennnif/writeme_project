'use client'

import { useState, useRef, useEffect } from 'react'
import { motion } from 'framer-motion'

export default function VoiceRecorder({ onTranscriptChange, onRecordingComplete }) {
  const [isRecording, setIsRecording] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const [transcript, setTranscript] = useState('')
  const [interimTranscript, setInterimTranscript] = useState('')
  const [error, setError] = useState(null)
  const [recordingTime, setRecordingTime] = useState(0)
  const [volume, setVolume] = useState(0)

  const mediaRecorderRef = useRef(null)
  const recognitionRef = useRef(null)
  const audioChunksRef = useRef([])
  const timerRef = useRef(null)
  const analyserRef = useRef(null)
  const audioContextRef = useRef(null)

  useEffect(() => {
    // Speech Recognition ì„¤ì •
    if (typeof window !== 'undefined' && 'webkitSpeechRecognition' in window) {
      const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition
      recognitionRef.current = new SpeechRecognition()
      
      recognitionRef.current.continuous = true
      recognitionRef.current.interimResults = true
      recognitionRef.current.lang = 'ko-KR'

      recognitionRef.current.onresult = (event) => {
        let finalTranscript = ''
        let interimTranscript = ''

        for (let i = event.resultIndex; i < event.results.length; i++) {
          if (event.results[i].isFinal) {
            finalTranscript += event.results[i][0].transcript
          } else {
            interimTranscript += event.results[i][0].transcript
          }
        }

        // ì„ì‹œ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        setInterimTranscript(interimTranscript)
        
        // í™•ì •ëœ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        if (finalTranscript) {
          setTranscript(prevTranscript => prevTranscript + finalTranscript)
        }
      }

      recognitionRef.current.onerror = (event) => {
        console.error('Speech recognition error:', event.error)
        setError('ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.')
      }

      recognitionRef.current.onstart = () => {
        console.log('Speech recognition started')
        setError(null)
      }

      recognitionRef.current.onend = () => {
        console.log('Speech recognition ended')
        if (isRecording) {
          // ë…¹ìŒ ì¤‘ì´ë¼ë©´ ë‹¤ì‹œ ì‹œì‘
          try {
            recognitionRef.current.start()
          } catch (error) {
            console.log('Failed to restart recognition:', error)
          }
        }
      }
    } else {
      setError('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')
    }

    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current)
      }
      // AudioContext ì •ë¦¬ëŠ” stopRecordingì—ì„œ ì²˜ë¦¬
    }
  }, [onTranscriptChange])

  // transcript ìƒíƒœê°€ ë³€ê²½ë  ë•Œë§ˆë‹¤ ìƒìœ„ ì»´í¬ë„ŒíŠ¸ì— ì „ë‹¬
  useEffect(() => {
    const fullText = (transcript + interimTranscript).trim()
    if (fullText) {
      onTranscriptChange?.(fullText)
    }
  }, [transcript, interimTranscript, onTranscriptChange])

  // ë³¼ë¥¨ ì¸¡ì •
  const setupVolumeMonitoring = (stream) => {
    try {
      // ê¸°ì¡´ AudioContextê°€ ìˆë‹¤ë©´ ì •ë¦¬
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close()
      }

      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)()
      const source = audioContextRef.current.createMediaStreamSource(stream)
      analyserRef.current = audioContextRef.current.createAnalyser()
      
      analyserRef.current.fftSize = 256
      source.connect(analyserRef.current)

      const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount)
      
      const updateVolume = () => {
        if (analyserRef.current && isRecording && audioContextRef.current && audioContextRef.current.state === 'running') {
          analyserRef.current.getByteFrequencyData(dataArray)
          const average = dataArray.reduce((a, b) => a + b) / dataArray.length
          setVolume(average)
          requestAnimationFrame(updateVolume)
        }
      }
      
      updateVolume()
    } catch (error) {
      console.error('ë³¼ë¥¨ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì˜¤ë¥˜:', error)
    }
  }

  const startRecording = async () => {
    try {
      setError(null)
      setIsProcessing(true)

      // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100
        } 
      })

      // MediaRecorder ì„¤ì •
      mediaRecorderRef.current = new MediaRecorder(stream, {
        mimeType: 'audio/webm'
      })

      audioChunksRef.current = []

      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data)
        }
      }

      mediaRecorderRef.current.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' })
        onRecordingComplete?.(audioBlob)
        
        // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        stream.getTracks().forEach(track => track.stop())
      }

      // ë³¼ë¥¨ ëª¨ë‹ˆí„°ë§ ì„¤ì •
      setupVolumeMonitoring(stream)

      // ë…¹ìŒ ì‹œì‘
      mediaRecorderRef.current.start(1000) // 1ì´ˆë§ˆë‹¤ data ì´ë²¤íŠ¸ ë°œìƒ
      
      // Speech Recognition ì‹œì‘
      if (recognitionRef.current) {
        try {
          recognitionRef.current.start()
        } catch (error) {
          console.error('Speech recognition start error:', error)
          setError('ìŒì„± ì¸ì‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        }
      }

      setIsRecording(true)
      setIsProcessing(false)
      setRecordingTime(0)
      
      // ë…¹ìŒ ì‹œì‘ì‹œ ê¸°ì¡´ í…ìŠ¤íŠ¸ ìœ ì§€í•˜ë˜ interimë§Œ ì´ˆê¸°í™”
      setInterimTranscript('')

      // íƒ€ì´ë¨¸ ì‹œì‘
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1)
      }, 1000)

    } catch (error) {
      console.error('ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:', error)
      setError('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.')
      setIsProcessing(false)
    }
  }

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop()
    }

    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop()
      } catch (error) {
        console.log('Speech recognition already stopped')
      }
    }

    if (timerRef.current) {
      clearInterval(timerRef.current)
      timerRef.current = null
    }

    // AudioContext ì•ˆì „í•˜ê²Œ ë‹«ê¸°
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      try {
        audioContextRef.current.close()
      } catch (error) {
        console.log('AudioContext already closed')
      }
      audioContextRef.current = null
    }

    setIsRecording(false)
    setVolume(0)
    setInterimTranscript('')
  }

  const formatTime = (seconds) => {
    const mins = Math.floor(seconds / 60)
    const secs = seconds % 60
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
  }

  const clearTranscript = () => {
    setTranscript('')
    setInterimTranscript('')
    onTranscriptChange?.('')
  }

  return (
    <div className="bg-white rounded-2xl shadow-lg p-6">
      <div className="text-center mb-6">
        <h3 className="text-xl font-semibold text-gray-900 mb-2">ìŒì„± ë‹µë³€ ë…¹ìŒ</h3>
        <p className="text-gray-600 text-sm">
          ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‹µë³€ì„ ë…¹ìŒí•˜ê³ , ì‹¤ì‹œê°„ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë©ë‹ˆë‹¤
        </p>
      </div>

      {/* ì—ëŸ¬ ë©”ì‹œì§€ */}
      {error && (
        <div className="mb-4 p-3 bg-red-50 border border-red-200 rounded-lg">
          <p className="text-red-700 text-sm">{error}</p>
        </div>
      )}

      {/* ë…¹ìŒ ì»¨íŠ¸ë¡¤ */}
      <div className="flex flex-col items-center mb-6">
        {/* ë©”ì¸ ë…¹ìŒ ë²„íŠ¼ */}
        <motion.button
          whileHover={{ scale: isRecording ? 1 : 1.05 }}
          whileTap={{ scale: 0.95 }}
          onClick={isRecording ? stopRecording : startRecording}
          disabled={isProcessing}
          className={`w-20 h-20 rounded-full flex items-center justify-center transition-all duration-300 ${
            isRecording 
              ? 'bg-red-500 hover:bg-red-600' 
              : 'bg-indigo-500 hover:bg-indigo-600'
          } disabled:opacity-50 relative overflow-hidden`}
        >
          {isProcessing ? (
            <div className="w-6 h-6 border-2 border-white border-t-transparent rounded-full animate-spin" />
          ) : (
            <>
              {/* ë³¼ë¥¨ ì‹œê°í™” */}
              {isRecording && (
                <motion.div
                  className="absolute inset-0 bg-white rounded-full"
                  animate={{ 
                    scale: 1 + (volume / 255) * 0.3,
                    opacity: 0.1 + (volume / 255) * 0.2 
                  }}
                  transition={{ duration: 0.1 }}
                />
              )}
              
              <svg className="w-8 h-8 text-white" fill="currentColor" viewBox="0 0 24 24">
                {isRecording ? (
                  <rect x="6" y="6" width="12" height="12" rx="2" />
                ) : (
                  <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z M17.3 11c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.49 6-3.31 6-6.72h-1.7z" />
                )}
              </svg>
            </>
          )}
        </motion.button>

        {/* ë…¹ìŒ ì‹œê°„ */}
        {isRecording && (
          <motion.div
            initial={{ opacity: 0, y: 10 }}
            animate={{ opacity: 1, y: 0 }}
            className="mt-4 flex items-center space-x-2"
          >
            <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse" />
            <span className="text-lg font-mono text-gray-700">
              {formatTime(recordingTime)}
            </span>
          </motion.div>
        )}

        {/* ìƒíƒœ í…ìŠ¤íŠ¸ */}
        <p className="mt-3 text-sm text-gray-600">
          {isProcessing ? 'ì¤€ë¹„ ì¤‘...' : 
           isRecording ? 'ë…¹ìŒ ì¤‘... (ë‹¤ì‹œ í´ë¦­í•˜ì—¬ ì¤‘ì§€)' : 
           'í´ë¦­í•˜ì—¬ ë…¹ìŒ ì‹œì‘'}
        </p>
      </div>

      {/* í…ŒìŠ¤íŠ¸ìš© ë²„íŠ¼ - ê°œë°œ í™˜ê²½ì—ì„œë§Œ í‘œì‹œ */}
      {process.env.NODE_ENV === 'development' && (
        <div className="mt-4 p-3 bg-blue-50 rounded-lg border border-blue-200">
          <p className="text-xs text-blue-700 mb-2">ê°œë°œ í…ŒìŠ¤íŠ¸ìš©</p>
          <button
            onClick={() => {
              const testText = "ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ. ì €ëŠ” í…ŒìŠ¤íŠ¸ ë‹µë³€ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤."
              setTranscript(testText)
              onTranscriptChange?.(testText)
            }}
            className="px-3 py-1 bg-blue-500 text-white text-xs rounded hover:bg-blue-600"
          >
            í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ì¶”ê°€
          </button>
        </div>
      )}

      {/* ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë³€í™˜ ê²°ê³¼ */}
      {transcript && (
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          className="border-t pt-4"
        >
          <div className="flex justify-between items-center mb-3">
            <h4 className="font-medium text-gray-900">ì‹¤ì‹œê°„ ë³€í™˜ í…ìŠ¤íŠ¸</h4>
            <button
              onClick={clearTranscript}
              className="text-sm text-gray-500 hover:text-gray-700 transition-colors"
            >
              ì§€ìš°ê¸°
            </button>
          </div>
          <div className="max-h-32 overflow-y-auto p-3 bg-gray-50 rounded-lg">
            <p className="text-gray-800 text-sm leading-relaxed whitespace-pre-wrap">
              <span>{transcript}</span>
              <span className="text-gray-500 italic">{interimTranscript}</span>
              {!transcript && !interimTranscript && (
                <span className="text-gray-400">ìŒì„±ì„ ì¸ì‹í•˜ëŠ” ì¤‘...</span>
              )}
            </p>
          </div>
          <p className="text-xs text-gray-500 mt-2">
            ğŸ’¡ ë” ì •í™•í•œ ì¸ì‹ì„ ìœ„í•´ ëª…í™•í•˜ê²Œ ë°œìŒí•´ì£¼ì„¸ìš”
          </p>
        </motion.div>
      )}
    </div>
  )
} 