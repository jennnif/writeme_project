'use client'

import { useState, useRef, useEffect } from 'react'
import { motion } from 'framer-motion'
import { analyzeTranscriptWithGemini, getRealtimeFeedback } from '../lib/gemini'

export default function VoiceRecorder({ onTranscriptChange, onRecordingComplete, onAIAnalysis }) {
  const [isRecording, setIsRecording] = useState(false)
  const [isProcessing, setIsProcessing] = useState(false)
  const [transcript, setTranscript] = useState('')
  const [interimTranscript, setInterimTranscript] = useState('')
  const [error, setError] = useState(null)
  const [recordingTime, setRecordingTime] = useState(0)
  const [volume, setVolume] = useState(0)
  
  // Gemini AI ê´€ë ¨ ìƒíƒœ
  const [aiAnalysis, setAiAnalysis] = useState(null)
  const [isAnalyzing, setIsAnalyzing] = useState(false)
  const [realtimeFeedback, setRealtimeFeedback] = useState(null)

  const mediaRecorderRef = useRef(null)
  const recognitionRef = useRef(null)
  const audioChunksRef = useRef([])
  const timerRef = useRef(null)
  const analyserRef = useRef(null)
  const audioContextRef = useRef(null)
  const feedbackTimeoutRef = useRef(null)

  useEffect(() => {
    // Speech Recognition ì„¤ì •
    if (typeof window !== 'undefined' && 'webkitSpeechRecognition' in window) {
      const SpeechRecognition = window.webkitSpeechRecognition || window.SpeechRecognition
      recognitionRef.current = new SpeechRecognition()
      
      recognitionRef.current.continuous = true
      recognitionRef.current.interimResults = true
      recognitionRef.current.lang = 'ko-KR'

      recognitionRef.current.onresult = (event) => {
        let finalTranscript = ''
        let interimTranscript = ''

        for (let i = event.resultIndex; i < event.results.length; i++) {
          if (event.results[i].isFinal) {
            finalTranscript += event.results[i][0].transcript
          } else {
            interimTranscript += event.results[i][0].transcript
          }
        }

        // ì„ì‹œ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        setInterimTranscript(interimTranscript)
        
        // í™•ì •ëœ í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ë° ì¦‰ì‹œ ìƒìœ„ ì»´í¬ë„ŒíŠ¸ì— ì „ë‹¬
        if (finalTranscript) {
          setTranscript(prevTranscript => {
            const newTranscript = prevTranscript + finalTranscript
            // ì¦‰ì‹œ ìƒìœ„ ì»´í¬ë„ŒíŠ¸ì— ì „ë‹¬
            setTimeout(() => {
              onTranscriptChange?.(newTranscript + interimTranscript)
            }, 0)
            
            // Gemini AI ë¶„ì„ íŠ¸ë¦¬ê±° (ì™„ë£Œëœ ë¬¸ì¥ì— ëŒ€í•´)
            triggerAIAnalysis(newTranscript)
            
            return newTranscript
          })
        } else if (interimTranscript) {
          // ì„ì‹œ í…ìŠ¤íŠ¸ë§Œ ìˆì–´ë„ ìƒìœ„ ì»´í¬ë„ŒíŠ¸ì— ì „ë‹¬
          setTimeout(() => {
            onTranscriptChange?.(transcript + interimTranscript)
          }, 0)
          
          // ì‹¤ì‹œê°„ í”¼ë“œë°± (ë””ë°”ìš´ì‹±)
          triggerRealtimeFeedback(transcript + interimTranscript)
        }
      }

      recognitionRef.current.onerror = (event) => {
        console.error('Speech recognition error:', event.error)
        setError('ìŒì„± ì¸ì‹ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë§ˆì´í¬ ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.')
      }

      recognitionRef.current.onstart = () => {
        console.log('Speech recognition started')
        setError(null)
      }

      recognitionRef.current.onend = () => {
        console.log('Speech recognition ended')
        if (isRecording) {
          // ë…¹ìŒ ì¤‘ì´ë¼ë©´ ë‹¤ì‹œ ì‹œì‘
          try {
            recognitionRef.current.start()
          } catch (error) {
            console.log('Failed to restart recognition:', error)
          }
        }
      }
    } else {
      setError('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')
    }

    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current)
      }
      if (feedbackTimeoutRef.current) {
        clearTimeout(feedbackTimeoutRef.current)
      }
      // AudioContext ì •ë¦¬ëŠ” stopRecordingì—ì„œ ì²˜ë¦¬
    }
  }, [onTranscriptChange])

  // transcript ìƒíƒœê°€ ë³€ê²½ë  ë•Œë§ˆë‹¤ ìƒìœ„ ì»´í¬ë„ŒíŠ¸ì— ì „ë‹¬
  useEffect(() => {
    const fullText = (transcript + interimTranscript).trim()
    if (fullText) {
      onTranscriptChange?.(fullText)
    }
  }, [transcript, interimTranscript])

  // ë³¼ë¥¨ ì¸¡ì •
  const setupVolumeMonitoring = (stream) => {
    try {
      // ê¸°ì¡´ AudioContextê°€ ìˆë‹¤ë©´ ì •ë¦¬
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContextRef.current.close()
      }

      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)()
      const source = audioContextRef.current.createMediaStreamSource(stream)
      analyserRef.current = audioContextRef.current.createAnalyser()
      
      analyserRef.current.fftSize = 256
      source.connect(analyserRef.current)

      const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount)
      
      const updateVolume = () => {
        if (analyserRef.current && isRecording && audioContextRef.current && audioContextRef.current.state === 'running') {
          analyserRef.current.getByteFrequencyData(dataArray)
          const average = dataArray.reduce((a, b) => a + b) / dataArray.length
          setVolume(average)
          requestAnimationFrame(updateVolume)
        }
      }
      
      updateVolume()
    } catch (error) {
      console.error('ë³¼ë¥¨ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì˜¤ë¥˜:', error)
    }
  }

  const startRecording = async () => {
    try {
      setError(null)
      setIsProcessing(true)

      // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100
        } 
      })

      // MediaRecorder ì„¤ì •
      mediaRecorderRef.current = new MediaRecorder(stream, {
        mimeType: 'audio/webm'
      })

      audioChunksRef.current = []

      mediaRecorderRef.current.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data)
        }
      }

      mediaRecorderRef.current.onstop = () => {
        const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' })
        onRecordingComplete?.(audioBlob)
        
        // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        stream.getTracks().forEach(track => track.stop())
      }

      // ë³¼ë¥¨ ëª¨ë‹ˆí„°ë§ ì„¤ì •
      setupVolumeMonitoring(stream)

      // ë…¹ìŒ ì‹œì‘
      mediaRecorderRef.current.start(1000) // 1ì´ˆë§ˆë‹¤ data ì´ë²¤íŠ¸ ë°œìƒ
      
      // Speech Recognition ì‹œì‘
      if (recognitionRef.current) {
        try {
          recognitionRef.current.start()
        } catch (error) {
          console.error('Speech recognition start error:', error)
          setError('ìŒì„± ì¸ì‹ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        }
      }

      setIsRecording(true)
      setIsProcessing(false)
      setRecordingTime(0)
      
      // ë…¹ìŒ ì‹œì‘ì‹œ ê¸°ì¡´ í…ìŠ¤íŠ¸ ìœ ì§€í•˜ë˜ interimë§Œ ì´ˆê¸°í™”
      setInterimTranscript('')

      // íƒ€ì´ë¨¸ ì‹œì‘
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1)
      }, 1000)

    } catch (error) {
      console.error('ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:', error)
      setError('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.')
      setIsProcessing(false)
    }
  }

  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop()
    }

    if (recognitionRef.current) {
      try {
        recognitionRef.current.stop()
      } catch (error) {
        console.log('Speech recognition already stopped')
      }
    }

    if (timerRef.current) {
      clearInterval(timerRef.current)
      timerRef.current = null
    }

    // AudioContext ì•ˆì „í•˜ê²Œ ë‹«ê¸°
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      try {
        audioContextRef.current.close()
      } catch (error) {
        console.log('AudioContext already closed')
      }
      audioContextRef.current = null
    }

    setIsRecording(false)
    setVolume(0)
    setInterimTranscript('')
  }

  const formatTime = (seconds) => {
    const mins = Math.floor(seconds / 60)
    const secs = seconds % 60
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`
  }

  const clearTranscript = () => {
    setTranscript('')
    setInterimTranscript('')
    onTranscriptChange?.('')
  }

  // Gemini AI ë¶„ì„ íŠ¸ë¦¬ê±° (ì™„ë£Œëœ ë¬¸ì¥)
  const triggerAIAnalysis = async (fullTranscript) => {
    if (!fullTranscript || fullTranscript.length < 20) return
    
    setIsAnalyzing(true)
    try {
      const analysis = await analyzeTranscriptWithGemini(fullTranscript, 'ë©´ì ‘')
      if (analysis) {
        setAiAnalysis(analysis)
        onAIAnalysis?.(analysis)
        console.log('Gemini ë¶„ì„ ê²°ê³¼:', analysis)
      }
    } catch (error) {
      console.error('AI ë¶„ì„ ì˜¤ë¥˜:', error)
    } finally {
      setIsAnalyzing(false)
    }
  }

  // ì‹¤ì‹œê°„ í”¼ë“œë°± íŠ¸ë¦¬ê±° (ë””ë°”ìš´ì‹±)
  const triggerRealtimeFeedback = (currentText) => {
    if (feedbackTimeoutRef.current) {
      clearTimeout(feedbackTimeoutRef.current)
    }
    
    feedbackTimeoutRef.current = setTimeout(async () => {
      if (currentText && currentText.length > 10) {
        try {
          const feedback = await getRealtimeFeedback(currentText)
          if (feedback) {
            setRealtimeFeedback(feedback)
          }
        } catch (error) {
          console.error('ì‹¤ì‹œê°„ í”¼ë“œë°± ì˜¤ë¥˜:', error)
        }
      }
    }, 2000) // 2ì´ˆ ë””ë°”ìš´ì‹±
  }

  return (
    <div className="bg-white rounded-2xl shadow-lg p-6">
      <div className="text-center mb-6">
        <h3 className="text-xl font-semibold text-gray-900 mb-2">ìŒì„± ë‹µë³€ ë…¹ìŒ</h3>
        <p className="text-gray-600 text-sm">
          ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‹µë³€ì„ ë…¹ìŒí•˜ê³ , ì‹¤ì‹œê°„ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë©ë‹ˆë‹¤
        </p>
      </div>

      {/* ì—ëŸ¬ ë©”ì‹œì§€ */}
      {error && (
        <div className="mb-4 p-3 bg-red-50 border border-red-200 rounded-lg">
          <p className="text-red-700 text-sm">{error}</p>
        </div>
      )}

      {/* ì‹¤ì‹œê°„ AI í”¼ë“œë°± */}
      {realtimeFeedback && isRecording && (
        <motion.div
          initial={{ opacity: 0, y: -10 }}
          animate={{ opacity: 1, y: 0 }}
          className="mb-4 p-3 rounded-lg border-l-4 border-blue-400 bg-blue-50"
        >
          <div className="flex items-center space-x-2">
            <div className={`w-2 h-2 rounded-full ${
              realtimeFeedback.status === 'good' ? 'bg-green-500' :
              realtimeFeedback.status === 'warning' ? 'bg-yellow-500' : 'bg-red-500'
            }`} />
            <p className="text-blue-800 text-sm font-medium">{realtimeFeedback.message}</p>
          </div>
          {realtimeFeedback.tip && (
            <p className="text-blue-600 text-xs mt-1">ğŸ’¡ {realtimeFeedback.tip}</p>
          )}
        </motion.div>
      )}

      {/* ë…¹ìŒ ì»¨íŠ¸ë¡¤ */}
      <div className="flex flex-col items-center mb-6">
        {/* ë©”ì¸ ë…¹ìŒ ë²„íŠ¼ */}
        <motion.button
          whileHover={{ scale: isRecording ? 1 : 1.05 }}
          whileTap={{ scale: 0.95 }}
          onClick={isRecording ? stopRecording : startRecording}
          disabled={isProcessing}
          className={`w-20 h-20 rounded-full flex items-center justify-center transition-all duration-300 ${
            isRecording 
              ? 'bg-red-500 hover:bg-red-600' 
              : 'bg-indigo-500 hover:bg-indigo-600'
          } disabled:opacity-50 relative overflow-hidden`}
        >
          {isProcessing ? (
            <div className="w-6 h-6 border-2 border-white border-t-transparent rounded-full animate-spin" />
          ) : (
            <>
              {/* ë³¼ë¥¨ ì‹œê°í™” */}
              {isRecording && (
                <motion.div
                  className="absolute inset-0 bg-white rounded-full"
                  animate={{ 
                    scale: 1 + (volume / 255) * 0.3,
                    opacity: 0.1 + (volume / 255) * 0.2 
                  }}
                  transition={{ duration: 0.1 }}
                />
              )}
              
              <svg className="w-8 h-8 text-white" fill="currentColor" viewBox="0 0 24 24">
                {isRecording ? (
                  <rect x="6" y="6" width="12" height="12" rx="2" />
                ) : (
                  <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z M17.3 11c0 3-2.54 5.1-5.3 5.1S6.7 14 6.7 11H5c0 3.41 2.72 6.23 6 6.72V21h2v-3.28c3.28-.49 6-3.31 6-6.72h-1.7z" />
                )}
              </svg>
            </>
          )}
        </motion.button>

        {/* AI ë¶„ì„ ìƒíƒœ */}
        {isAnalyzing && (
          <motion.div
            initial={{ opacity: 0, y: 10 }}
            animate={{ opacity: 1, y: 0 }}
            className="mt-3 flex items-center space-x-2 text-purple-600"
          >
            <div className="w-4 h-4 border-2 border-purple-600 border-t-transparent rounded-full animate-spin" />
            <span className="text-sm font-medium">Gemini AI ë¶„ì„ ì¤‘...</span>
          </motion.div>
        )}

        {/* ë…¹ìŒ ì‹œê°„ */}
        {isRecording && (
          <motion.div
            initial={{ opacity: 0, y: 10 }}
            animate={{ opacity: 1, y: 0 }}
            className="mt-4 flex items-center space-x-2"
          >
            <div className="w-3 h-3 bg-red-500 rounded-full animate-pulse" />
            <span className="text-lg font-mono text-gray-700">
              {formatTime(recordingTime)}
            </span>
          </motion.div>
        )}

        {/* ìƒíƒœ í…ìŠ¤íŠ¸ */}
        <p className="mt-3 text-sm text-gray-600">
          {isProcessing ? 'ì¤€ë¹„ ì¤‘...' : 
           isRecording ? 'ë…¹ìŒ ì¤‘... (ë‹¤ì‹œ í´ë¦­í•˜ì—¬ ì¤‘ì§€)' : 
           'í´ë¦­í•˜ì—¬ ë…¹ìŒ ì‹œì‘'}
        </p>
      </div>

      {/* Gemini AI ë¶„ì„ ê²°ê³¼ */}
      {aiAnalysis && !aiAnalysis.error && (
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          className="mb-6 bg-gradient-to-r from-purple-50 to-blue-50 rounded-2xl p-6 border border-purple-200"
        >
          <div className="flex items-center space-x-2 mb-4">
            <svg className="w-5 h-5 text-purple-600" fill="currentColor" viewBox="0 0 24 24">
              <path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm-2 15l-5-5 1.41-1.41L10 14.17l7.59-7.59L19 8l-9 9z"/>
            </svg>
            <h4 className="font-semibold text-purple-900">ğŸ¤– Gemini AI ë¶„ì„ ê²°ê³¼</h4>
            {aiAnalysis.score && (
              <span className="ml-auto bg-purple-100 text-purple-700 px-3 py-1 rounded-full text-sm font-medium">
                {aiAnalysis.score}ì 
              </span>
            )}
          </div>

          {aiAnalysis.analysis && (
            <div className="mb-4">
              <p className="text-purple-800 leading-relaxed">{aiAnalysis.analysis}</p>
            </div>
          )}

          {aiAnalysis.tone && (
            <div className="mb-3">
              <span className="text-sm font-medium text-purple-700">ë§íˆ¬ ë¶„ì„: </span>
              <span className="text-purple-600">{aiAnalysis.tone}</span>
            </div>
          )}

          {aiAnalysis.key_points && aiAnalysis.key_points.length > 0 && (
            <div className="mb-3">
              <p className="text-sm font-medium text-purple-700 mb-2">í•µì‹¬ í¬ì¸íŠ¸:</p>
              <ul className="space-y-1">
                {aiAnalysis.key_points.map((point, index) => (
                  <li key={index} className="text-sm text-purple-600 flex items-start">
                    <span className="text-purple-400 mr-2">â€¢</span>
                    {point}
                  </li>
                ))}
              </ul>
            </div>
          )}

          {aiAnalysis.suggestions && aiAnalysis.suggestions.length > 0 && (
            <div>
              <p className="text-sm font-medium text-purple-700 mb-2">ê°œì„  ì œì•ˆ:</p>
              <ul className="space-y-1">
                {aiAnalysis.suggestions.map((suggestion, index) => (
                  <li key={index} className="text-sm text-purple-600 flex items-start">
                    <span className="text-yellow-500 mr-2">ğŸ’¡</span>
                    {suggestion}
                  </li>
                ))}
              </ul>
            </div>
          )}

          {aiAnalysis.confidence && (
            <div className="mt-4 pt-3 border-t border-purple-200">
              <div className="flex items-center justify-between text-xs text-purple-600">
                <span>AI ì‹ ë¢°ë„</span>
                <span>{Math.round(aiAnalysis.confidence * 100)}%</span>
              </div>
              <div className="w-full bg-purple-200 rounded-full h-1.5 mt-1">
                <div 
                  className="bg-purple-500 h-1.5 rounded-full transition-all duration-500"
                  style={{ width: `${aiAnalysis.confidence * 100}%` }}
                />
              </div>
            </div>
          )}
        </motion.div>
      )}

      {/* AI ì˜¤ë¥˜ ë©”ì‹œì§€ */}
      {aiAnalysis?.error && (
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          className="mb-6 p-4 bg-red-50 border border-red-200 rounded-lg"
        >
          <p className="text-red-700 text-sm">{aiAnalysis.message}</p>
          {aiAnalysis.suggestions && (
            <ul className="mt-2 space-y-1">
              {aiAnalysis.suggestions.map((suggestion, index) => (
                <li key={index} className="text-red-600 text-xs">â€¢ {suggestion}</li>
              ))}
            </ul>
          )}
        </motion.div>
      )}

      {/* í…ŒìŠ¤íŠ¸ìš© ë²„íŠ¼ - í•­ìƒ í‘œì‹œ */}
      <div className="mt-4 p-3 bg-blue-50 rounded-lg border border-blue-200">
        <p className="text-xs text-blue-700 mb-2">í…ŒìŠ¤íŠ¸ìš© (ìŒì„± ì¸ì‹ì´ ì•ˆ ë  ë•Œ ì‚¬ìš©)</p>
        <div className="space-y-2">
          <button
            onClick={() => {
              const testText = "ì•ˆë…•í•˜ì‹­ë‹ˆê¹Œ. ì €ëŠ” ì°½ì˜ì  ë¬¸ì œí•´ê²°ê³¼ íŒ€ì›Œí¬ë¥¼ ì¤‘ì‹œí•˜ëŠ” ì§€ì›ìì…ë‹ˆë‹¤. ëŒ€í•™ì—ì„œ ê²½ì˜í•™ì„ ì „ê³µí•˜ë©° ë‹¤ì–‘í•œ í”„ë¡œì íŠ¸ ê²½í—˜ì„ ìŒ“ì•˜ìŠµë‹ˆë‹¤."
              console.log('í…ŒìŠ¤íŠ¸ ë²„íŠ¼ í´ë¦­ë¨, í…ìŠ¤íŠ¸:', testText)
              setTranscript(testText)
              setInterimTranscript('')
              onTranscriptChange?.(testText)
              console.log('onTranscriptChange í˜¸ì¶œë¨')
            }}
            className="px-3 py-1 bg-blue-500 text-white text-xs rounded hover:bg-blue-600 mr-2"
          >
            ìê¸°ì†Œê°œ ì˜ˆì‹œ ì¶”ê°€
          </button>
          <button
            onClick={() => {
              setTranscript('')
              setInterimTranscript('')
              onTranscriptChange?.('')
            }}
            className="px-3 py-1 bg-gray-500 text-white text-xs rounded hover:bg-gray-600"
          >
            í…ìŠ¤íŠ¸ ì§€ìš°ê¸°
          </button>
        </div>
      </div>

      {/* ì‹¤ì‹œê°„ í…ìŠ¤íŠ¸ ë³€í™˜ ê²°ê³¼ */}
      {transcript && (
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          className="border-t pt-4"
        >
          <div className="flex justify-between items-center mb-3">
            <h4 className="font-medium text-gray-900">ì‹¤ì‹œê°„ ë³€í™˜ í…ìŠ¤íŠ¸</h4>
            <button
              onClick={clearTranscript}
              className="text-sm text-gray-500 hover:text-gray-700 transition-colors"
            >
              ì§€ìš°ê¸°
            </button>
          </div>
          <div className="max-h-32 overflow-y-auto p-3 bg-gray-50 rounded-lg">
            <p className="text-gray-800 text-sm leading-relaxed whitespace-pre-wrap">
              <span>{transcript}</span>
              <span className="text-gray-500 italic">{interimTranscript}</span>
              {!transcript && !interimTranscript && (
                <span className="text-gray-400">ìŒì„±ì„ ì¸ì‹í•˜ëŠ” ì¤‘...</span>
              )}
            </p>
          </div>
          <p className="text-xs text-gray-500 mt-2">
            ğŸ’¡ ë” ì •í™•í•œ ì¸ì‹ì„ ìœ„í•´ ëª…í™•í•˜ê²Œ ë°œìŒí•´ì£¼ì„¸ìš”
          </p>
        </motion.div>
      )}
    </div>
  )
} 